{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4824afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9ef7f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:09.798174Z",
     "start_time": "2022-01-10T09:06:09.781360Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77243e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:10.808531Z",
     "start_time": "2022-01-10T09:06:09.800274Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.core.display import Markdown,display, HTML, Latex\n",
    "import qgrid\n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.patheffects as pe\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4406f4a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T06:17:26.003376Z",
     "start_time": "2022-01-10T06:17:25.980432Z"
    }
   },
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "from torch.multiprocessing import Pool, Process, set_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54540904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T04:46:12.820178Z",
     "start_time": "2022-01-10T04:46:12.222257Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56c044e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:10.823350Z",
     "start_time": "2022-01-10T09:06:10.810704Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_multi_nli = {0: 'contradiction', 1 : 'neutral', 2 : 'entailment'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fb8ea",
   "metadata": {},
   "source": [
    "## Load Paraphrased dataset to check opposition of semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5922b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:10.835223Z",
     "start_time": "2022-01-10T09:06:10.825363Z"
    }
   },
   "outputs": [],
   "source": [
    "cur_model_outcome_dir = '../../dfs_generated/paraphrased/paws/cumulative_tech_term_ner_ic/'\n",
    "cur_models_all_files =  glob.glob(os.path.join(cur_model_outcome_dir, '*.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0baa8628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:11.619511Z",
     "start_time": "2022-01-10T09:06:10.836841Z"
    }
   },
   "outputs": [],
   "source": [
    "list_cur_itr_model_dfs = []\n",
    "for cur_model_cur_file_name in cur_models_all_files:\n",
    "    tmp_df = pd.read_pickle(cur_model_cur_file_name)\n",
    "    tmp_df['file_name'] = os.path.basename(cur_model_cur_file_name)\n",
    "    list_cur_itr_model_dfs.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35678bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:11.701246Z",
     "start_time": "2022-01-10T09:06:11.621457Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cur_itr_model_all_res = pd.concat(list_cur_itr_model_dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50e3ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:06:11.736544Z",
     "start_time": "2022-01-10T09:06:11.704756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_11_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_1_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_10_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_9_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_0_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_4_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_1_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_3_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_7_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_8_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_5_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_4_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_5_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_3_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_2_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_refute_to_gen_support_2_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_0_FT_concat_prev.pkl',\n",
       "       'paws_base_no_fine_tune_ParaphraseTargetDirection.org_support_to_gen_refute_6_FT_concat_prev.pkl'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res['file_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be6b296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.880391Z",
     "start_time": "2022-01-10T09:06:11.738688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d850e197f89e40868096ea3fc519112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6870fb826447abb47db4ce0ce300ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a625e748480417abeb406073e04ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res['paraphrase_model'] = df_cur_itr_model_all_res['file_name'].progress_apply(lambda x: pd.Series(re.split('[_ .]',x)[0]))\n",
    "df_cur_itr_model_all_res['fine_tune_direction'] = df_cur_itr_model_all_res['file_name'].progress_apply(lambda x: pd.Series('_'.join(re.split('[_ .]',x)[6:11])))\n",
    "df_cur_itr_model_all_res['no_of_df_used_for_fine_tuned'] = df_cur_itr_model_all_res['file_name'].progress_apply(lambda x: pd.Series(re.split('[_ .]',x)[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ef5a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.893326Z",
     "start_time": "2022-01-10T09:07:17.882165Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_inc_dec = df_cur_itr_model_all_res[ (df_cur_itr_model_all_res['org_claim'].str.contains('increase'))\n",
    "#                         & (df_cur_itr_model_all_res['gen_claim'].str.contains('increase'))][['org_claim', 'gen_claim']]\n",
    "#df_inc_dec = df_cur_itr_model_all_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01845ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.903818Z",
     "start_time": "2022-01-10T09:07:17.894957Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_inc_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63d39258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.914204Z",
     "start_time": "2022-01-10T09:07:17.905408Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_inc_dec = df_inc_dec.groupby(['org_claim', 'gen_claim']).size().reset_index(name='Freq')[['org_claim', 'gen_claim']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440627f4",
   "metadata": {},
   "source": [
    "## Filter for technocal terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "192508a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.924965Z",
     "start_time": "2022-01-10T09:07:17.915933Z"
    }
   },
   "outputs": [],
   "source": [
    "loc_df_scispacy_sentence_word_unq_ner_abr_filtered ='../../dfs_generated/linguistic/df_scispacy_sentence_word_unq_ner_abr_filtered.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33fd3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.939535Z",
     "start_time": "2022-01-10T09:07:17.926622Z"
    }
   },
   "outputs": [],
   "source": [
    "df_scispacy_sentence_word_unq_ner_abr_filtered = pd.read_pickle(loc_df_scispacy_sentence_word_unq_ner_abr_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ec770b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:17.953106Z",
     "start_time": "2022-01-10T09:07:17.941518Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_and_replace_tech_term_paraphrased_claim(claim_paraphrased, claim_original):\n",
    "    #claim_para_trimmed = re.sub('[^a-z]+', ' ', claim_paraphrased.lower())\n",
    "    df_cur_sentence_word_unq_ner_abr_filtered = df_scispacy_sentence_word_unq_ner_abr_filtered[\n",
    "        df_scispacy_sentence_word_unq_ner_abr_filtered['claim'] == claim_original\n",
    "    ]\n",
    "    for cur_term_row in df_cur_sentence_word_unq_ner_abr_filtered.itertuples(index=False):\n",
    "        cur_term_row_formatted = r'\\b' + re.escape(cur_term_row.ner_text) + r'\\b'\n",
    "        if cur_term_row_formatted not in claim_paraphrased:\n",
    "            return False        \n",
    "#         if cur_term_row.ner_text.lower() not in claim_paraphrased.lower():\n",
    "#             return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12901e34",
   "metadata": {},
   "source": [
    "## Roberta Negetion Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21926d",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/69374258/sentence-similarity-models-not-capturing-opposite-sentences\n",
    "- https://github.com/pytorch/fairseq/tree/main/examples/roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54dd1027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:19.473889Z",
     "start_time": "2022-01-10T09:07:17.954912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 02:07:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ec4cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:19.500853Z",
     "start_time": "2022-01-10T09:07:19.475840Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9ba717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:35.415733Z",
     "start_time": "2022-01-10T09:07:19.502789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/qudratealahyratu/.cache/torch/hub/pytorch_fairseq_main\n",
      "2022-01-10 02:07:20 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.mnli.tar.gz from cache at /home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8\n",
      "2022-01-10 02:07:24 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2022-01-10 02:07:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_large', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, arch='roberta_large', attention_dropout=0.1, bagging=False, best_checkpoint_metric='accuracy', bpe='gpt2', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='masked_lm', curriculum=0, data='/home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8', dataset_impl='cached', ddp_backend='no_c10d', debug=False, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, ffn_reg_scale_factor=0.0, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_scale_tolerance=0.0, fp16_scale_window=128, global_sync_iter=10, init_token=0, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.0, layernorm_embedding=True, load_checkpoint_heads=True, log_format='json', log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_positions=512, max_sentences=32, max_sentences_valid=32, max_source_positions=512, max_target_positions=512, max_tokens=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, mha_reg_scale_factor=0.0, min_loss_scale=0.0001, min_params_to_wrap=100000000, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, no_scale_embedding=True, no_shuffle=False, no_token_positional_embeddings=False, num_classes=3, num_workers=3, optimizer='adam', optimizer_overrides='{}', pooler_activation_fn='tanh', pooler_dropout=0.3, power=1.0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, regression_target=False, remove_head=True, remove_sentence_classification_head=True, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_last.pt', save_interval=1, save_interval_updates=0, save_predictions=None, seed=8, sentence_avg=False, separator_token=2, skip_invalid_size_inputs_valid_test=False, spectral_norm_classification_head=False, stop_min_lr=-1, task='masked_lm', tbmf_wrapper=False, threshold_loss_scale=1.0, tokenizer=None, tokens_per_sample=512, total_num_update=123873, train_subset='train', truncate_sequence=False, untie_weights_roberta=False, update_freq=[1], use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=30968, weight_decay=0.1), 'task': {'_name': 'masked_lm', 'data': '/home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict(\n",
       "      (mnli): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_neg_checker_roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
    "\n",
    "model_neg_checker_roberta.to('cuda')\n",
    "#model_neg_checker_roberta.cuda()\n",
    "\n",
    "model_neg_checker_roberta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f972160b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:35.448701Z",
     "start_time": "2022-01-10T09:07:35.418177Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mlnli_label(org_claim, gen_claim):    \n",
    "    tokens_sentences_org_gen = model_neg_checker_roberta.encode(org_claim, gen_claim)\n",
    "    logprobs_sentences_org_gen = model_neg_checker_roberta.predict('mnli', tokens_sentences_org_gen)      \n",
    "    cal_val_mlnli_org_gen = logprobs_sentences_org_gen.argmax(dim=1).item()\n",
    "    cal_label_mlnli_org_gen = labels_multi_nli[cal_val_mlnli_org_gen]\n",
    "    \n",
    "    tokens_sentences_gen_org = model_neg_checker_roberta.encode(gen_claim, org_claim)\n",
    "    logprobs_sentences_gen_org = model_neg_checker_roberta.predict('mnli', tokens_sentences_gen_org)      \n",
    "    cal_val_mlnli_gen_org = logprobs_sentences_gen_org.argmax(dim=1).item()\n",
    "    cal_label_mlnli_gen_org = labels_multi_nli[cal_val_mlnli_gen_org]    \n",
    "    \n",
    "    return pd.Series([cal_val_mlnli_org_gen, cal_label_mlnli_org_gen, cal_val_mlnli_gen_org, cal_label_mlnli_gen_org])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba410ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:35.478041Z",
     "start_time": "2022-01-10T09:07:35.452726Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tiny_test = pd.DataFrame(\n",
    "[{'org_claim' : 'Antidepressants increase the severity of migraines.',\n",
    "  'gen_claim' : 'Antidepressants decrease the severity of migraines'},\n",
    " {'org_claim' : 'Antidepressants increase the severity of migraines.',\n",
    "  'gen_claim' : 'Antidepressants causes serious migraines'},\n",
    " {'org_claim' : 'Antidepressants increase the severity of migraines.',\n",
    "  'gen_claim' : 'Antidepressants is not an OTC drug.'},\n",
    "  {'org_claim' : 'Antimicrobial agents are less effective due to the pressure of antimicrobial usage.',\n",
    "  'gen_claim' : 'The antimicrobial drugs are less effective.'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2c2e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:35.719184Z",
     "start_time": "2022-01-10T09:07:35.480424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7749bf54e57149918a4c8c2b6b5c98b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_tiny_test[['mlnli_val_org_gen', 'mlnli_label_org_gen', 'mlnli_val_gen_org', 'mlnli_label_gen_org']] = df_tiny_test.progress_apply(lambda cur_row : get_mlnli_label (cur_row['org_claim'], cur_row['gen_claim']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a952f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T09:07:35.751928Z",
     "start_time": "2022-01-10T09:07:35.721226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_claim</th>\n",
       "      <th>gen_claim</th>\n",
       "      <th>mlnli_val_org_gen</th>\n",
       "      <th>mlnli_label_org_gen</th>\n",
       "      <th>mlnli_val_gen_org</th>\n",
       "      <th>mlnli_label_gen_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antidepressants increase the severity of migraines.</td>\n",
       "      <td>Antidepressants decrease the severity of migraines</td>\n",
       "      <td>0</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antidepressants increase the severity of migraines.</td>\n",
       "      <td>Antidepressants causes serious migraines</td>\n",
       "      <td>2</td>\n",
       "      <td>entailment</td>\n",
       "      <td>2</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antidepressants increase the severity of migraines.</td>\n",
       "      <td>Antidepressants is not an OTC drug.</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antimicrobial agents are less effective due to the pressure of antimicrobial usage.</td>\n",
       "      <td>The antimicrobial drugs are less effective.</td>\n",
       "      <td>2</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(df_tiny_test.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8bdbb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:26:54.551836Z",
     "start_time": "2022-01-10T09:07:35.755141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5e94481dc24ca9a20145d66a17ef16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res[['mlnli_val_org_gen', 'mlnli_label_org_gen', 'mlnli_val_gen_org', 'mlnli_label_gen_org']] = df_cur_itr_model_all_res.progress_apply(lambda cur_row : get_mlnli_label (cur_row['org_claim'], cur_row['gen_claim']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60bd3ef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:26:54.589753Z",
     "start_time": "2022-01-10T10:26:54.553723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       85424\n",
       "contradiction    17260\n",
       "neutral           6406\n",
       "Name: mlnli_label_org_gen, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res['mlnli_label_org_gen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8804d5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:26:54.718747Z",
     "start_time": "2022-01-10T10:26:54.591770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65851"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cur_itr_model_all_res[(df_cur_itr_model_all_res['mlnli_label_org_gen'] == 'entailment') &\n",
    "                        (df_cur_itr_model_all_res['mlnli_label_gen_org'] == 'entailment')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c9ceee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.446876Z",
     "start_time": "2022-01-10T10:26:54.720418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeade7388e9469b826f914adeda1130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res['passed_ner_abr_filter_ic'] = df_cur_itr_model_all_res.progress_apply(lambda x: filter_and_replace_tech_term_paraphrased_claim(x['gen_claim'], x['org_claim']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57d55b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.500169Z",
     "start_time": "2022-01-10T10:28:57.464127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    103273\n",
       "True       5817\n",
       "Name: passed_ner_abr_filter_ic, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res['passed_ner_abr_filter_ic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bc900aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.522944Z",
     "start_time": "2022-01-10T10:28:57.501887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109090, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cur_itr_model_all_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d549e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c19ef8",
   "metadata": {},
   "source": [
    "## Attack calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ded71932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.544677Z",
     "start_time": "2022-01-10T10:28:57.524502Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataframes_by_majority_org_claim(df_all_paraphrased_org_claim):\n",
    "    df_all_paraphrased_org_success = df_all_paraphrased_org_claim[df_all_paraphrased_org_claim['org_comment'] == 'success']\n",
    "    \n",
    "    # Select claims with majority\n",
    "    df_paraphrased_org_support_major = df_all_paraphrased_org_success[\n",
    "        df_all_paraphrased_org_success['org_count_support'] > df_all_paraphrased_org_success['org_count_refute']\n",
    "    ]\n",
    "\n",
    "    \n",
    "    df_paraphrased_org_refute_major = df_all_paraphrased_org_success[\n",
    "        df_all_paraphrased_org_success['org_count_support'] < df_all_paraphrased_org_success['org_count_refute']\n",
    "    ]\n",
    "    \n",
    "    return df_paraphrased_org_support_major, df_paraphrased_org_refute_major, df_all_paraphrased_org_success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2710e456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.567598Z",
     "start_time": "2022-01-10T10:28:57.546601Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_succesfully_attacked_claim(df_paraphrased_support_major, df_paraphrased_refute_major):\n",
    "    df_org_refute_gen_support = df_paraphrased_refute_major[\n",
    "    df_paraphrased_refute_major['gen_count_support'] > df_paraphrased_refute_major['gen_count_refute']\n",
    "    ]\n",
    "\n",
    "    df_org_support_gen_refute = df_paraphrased_support_major[\n",
    "        df_paraphrased_support_major['gen_count_support'] < df_paraphrased_support_major['gen_count_refute']\n",
    "    ]\n",
    "    \n",
    "    return df_org_support_gen_refute, df_org_refute_gen_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e3780b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.614171Z",
     "start_time": "2022-01-10T10:28:57.569879Z"
    }
   },
   "outputs": [],
   "source": [
    "df_paraphrased_selected_model_full = df_cur_itr_model_all_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b04750a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.717397Z",
     "start_time": "2022-01-10T10:28:57.615979Z"
    }
   },
   "outputs": [],
   "source": [
    "df_paraphrased_org_support_major, df_paraphrased_org_refute_major, df_all_paraphrased_cur_model_org_success = get_dataframes_by_majority_org_claim(df_paraphrased_selected_model_full)\n",
    "\n",
    "\n",
    "# Get successfullt attacked claims after paraphrased\n",
    "df_org_support_gen_refute, df_org_refute_gen_support = get_df_succesfully_attacked_claim(df_paraphrased_org_support_major, df_paraphrased_org_refute_major)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b836f4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.743758Z",
     "start_time": "2022-01-10T10:28:57.719067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qudratealahyratu/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/qudratealahyratu/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_org_support_gen_refute['attack_type'] = 'org_support_gen_refute' \n",
    "df_org_refute_gen_support['attack_type'] = 'org_refute_gen_support'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64ff1307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.777956Z",
     "start_time": "2022-01-10T10:28:57.745408Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all_attack = pd.concat([df_org_support_gen_refute, df_org_refute_gen_support])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "290fdeea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.803960Z",
     "start_time": "2022-01-10T10:28:57.779926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12685"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c3d4e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.839675Z",
     "start_time": "2022-01-10T10:28:57.805354Z"
    }
   },
   "outputs": [],
   "source": [
    " df_all_attack_filtered = df_all_attack[(df_all_attack['passed_ner_abr_filter_ic'] == True) &\n",
    "          (df_all_attack['mlnli_label_org_gen'] == 'entailment') &\n",
    "                                       (df_all_attack['mlnli_label_gen_org'] == 'entailment')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3565988f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.865275Z",
     "start_time": "2022-01-10T10:28:57.841391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_attack_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c17845a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.888106Z",
     "start_time": "2022-01-10T10:28:57.866797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_attack_filtered['org_claim'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7ac21cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.909640Z",
     "start_time": "2022-01-10T10:28:57.889519Z"
    }
   },
   "outputs": [],
   "source": [
    " df_all_attack_filtered_clm = df_all_attack_filtered[['org_claim', 'gen_claim', 'attack_type', 'fine_tune_direction',\n",
    "                                                       'model', 'no_of_df_used_for_fine_tuned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a83f141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:57.931434Z",
     "start_time": "2022-01-10T10:28:57.911609Z"
    }
   },
   "outputs": [],
   "source": [
    "loc_path_file_name = '../../dfs_generated/filter_applied/paws_tech_term_ner_ic/cumulative_tech_term_ner_ic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eef4f734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:58.029877Z",
     "start_time": "2022-01-10T10:28:57.933063Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all_attack_filtered_clm.to_csv(loc_path_file_name+'_all_filtered_attack_clm.csv')\n",
    "with open(loc_path_file_name+'_all_filtered_attack.pkl', 'wb') as fp:\n",
    "    pickle.dump(df_all_attack_filtered_clm, fp)\n",
    "    \n",
    "df_all_attack.to_pickle(loc_path_file_name+'_all_attack_filter_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fc3094f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:28:58.079437Z",
     "start_time": "2022-01-10T10:28:58.031650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rephrase =     109090 || # of unique original claim covered =        340\n",
      "Total attack =      12685 || # of unique original claim covered =        310\n",
      "Attack with org entailment =       6587 || # of unique original claim covered =        259\n",
      "Attack with both entailment =        521 || # of unique original claim covered =         17\n",
      "Attack with both entailment valid ner =        327 || # of unique original claim covered =         15\n"
     ]
    }
   ],
   "source": [
    "print('Total rephrase = {:10} || # of unique original claim covered = {:10}'.format(len(df_cur_itr_model_all_res), \n",
    "                                                                           len(df_cur_itr_model_all_res['org_claim'].value_counts().keys())))\n",
    "\n",
    "print('Total attack = {:10} || # of unique original claim covered = {:10}'.format(len(df_all_attack), \n",
    "                                                                                  len(df_all_attack['org_claim'].value_counts().keys())))\n",
    "\n",
    "print('Attack with org entailment = {:10} || # of unique original claim covered = {:10}'.format(len(df_all_attack[df_all_attack['mlnli_label_org_gen'] == 'entailment']), \n",
    "                                                                                  len(df_all_attack[df_all_attack['mlnli_label_org_gen'] == 'entailment']['org_claim'].value_counts().keys())))\n",
    "\n",
    "print('Attack with both entailment = {:10} || # of unique original claim covered = {:10}'.format(len(df_all_attack[(df_all_attack['passed_ner_abr_filter_ic'] == True) &\n",
    "          (df_all_attack['mlnli_label_org_gen'] == 'entailment')]), len(df_all_attack[(df_all_attack['passed_ner_abr_filter_ic'] == True) &\n",
    "          (df_all_attack['mlnli_label_org_gen'] == 'entailment')]['org_claim'].value_counts().keys())))\n",
    "\n",
    "print('Attack with both entailment valid ner = {:10} || # of unique original claim covered = {:10}'.format(len(df_all_attack_filtered), \n",
    "                                                                                  len(df_all_attack_filtered['org_claim'].value_counts().keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d9205",
   "metadata": {},
   "source": [
    "##### /paws/cumulative/\n",
    "Total rephrase =      55201 || # of unique original claim covered =        340\n",
    "\n",
    "Total attack =      11440 || # of unique original claim covered =        322\n",
    "\n",
    "Attack with org entailment =       5118 || # of unique original claim covered =        262\n",
    "\n",
    "Attack with both entailment =        342 || # of unique original claim covered =         14\n",
    "\n",
    "Attack with both entailment valid ner =        123 || # of unique original claim covered =         12\n",
    "\n",
    "##### /paws/cumulative_07_threshold/\n",
    "Total rephrase =      51796 || # of unique original claim covered =        340\n",
    "Total attack =       6072 || # of unique original claim covered =        277\n",
    "Attack with org entailment =       4242 || # of unique original claim covered =        242\n",
    "Attack with both entailment =        327 || # of unique original claim covered =         15\n",
    "Attack with both entailment valid ner =        136 || # of unique original claim covered =         13\n",
    "\n",
    "\n",
    "##### /paws/cumulative_tech_term_ner_ic/\n",
    "Total rephrase =     109090 || # of unique original claim covered =        340\n",
    "Total attack =      12685 || # of unique original claim covered =        310\n",
    "Attack with org entailment =       6587 || # of unique original claim covered =        259\n",
    "Attack with both entailment =        521 || # of unique original claim covered =         17\n",
    "Attack with both entailment valid ner =        327 || # of unique original claim covered =         15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51701648",
   "metadata": {},
   "source": [
    "##### /paws/cumulative/\n",
    "Total rephrase =      55201 || # of unique original claim covered =        340\n",
    "\n",
    "Total attack =      11440 || # of unique original claim covered =        322\n",
    "\n",
    "Attack with org entailment =       5118 || # of unique original claim covered =        262\n",
    "\n",
    "Attack with both entailment =        342 || # of unique original claim covered =         14\n",
    "\n",
    "Attack with both entailment valid ner =        123 || # of unique original claim covered =         12\n",
    "\n",
    "##### /paws/cumulative_07_threshold/\n",
    "Total rephrase =      51796 || # of unique original claim covered =        340\n",
    "Total attack =       6072 || # of unique original claim covered =        277\n",
    "Attack with org entailment =       4242 || # of unique original claim covered =        242\n",
    "Attack with both entailment =        327 || # of unique original claim covered =         15\n",
    "Attack with both entailment valid ner =        136 || # of unique original claim covered =         13\n",
    "\n",
    "\n",
    "##### /paws/cumulative_tech_term_ner_ic/\n",
    "Total rephrase =     109090 || # of unique original claim covered =        340\n",
    "Total attack =      12685 || # of unique original claim covered =        310\n",
    "Attack with org entailment =       6587 || # of unique original claim covered =        259\n",
    "Attack with both entailment =        521 || # of unique original claim covered =         17\n",
    "Attack with both entailment valid ner =        327 || # of unique original claim covered =         15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de92c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06785c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-09T06:51:37.591618Z",
     "start_time": "2022-01-09T06:51:37.560985Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "temp = 'This is correct'\n",
    "src_txt = r'\\b' + re.escape(temp) + r'\\b'\n",
    "if re.search(src_txt, 'This is correct and'):\n",
    "    print('correct')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scifact] *",
   "language": "python",
   "name": "conda-env-scifact-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
